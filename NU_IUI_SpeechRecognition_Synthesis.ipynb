{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNmluUwEa1Q36woEuUMT0Fx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Eaby/NLP_Codes/blob/main/NU_IUI_SpeechRecognition_Synthesis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Speech Recognition & Synthesis Application***\n",
        "\n",
        "********************************************************************************\n",
        "# **Task 1 : Speech Recognition**\n",
        "\n",
        "This code is a Python script that performs several tasks related to audio processing, language detection, sentiment analysis, and more from an audio file.\n",
        "\n",
        "A detailed description of the code is provided below:\n",
        "\n",
        ">**Libraries:**\n",
        "\n",
        ">>**drive:** This is used to mount Google Drive.\n",
        "\n",
        ">>**numpy:** Used for numerical operations.\n",
        "\n",
        ">>**matplotlib.pyplot:** Used for plotting.\n",
        "\n",
        ">>**gtts:** Google Text-to-Speech library for converting text to speech.\n",
        "\n",
        ">>**os:** Operating system-related functions.\n",
        "\n",
        ">>**fasttext:** Library for fast text classification and language detection.\n",
        "\n",
        ">>**transformers:** Part of the Hugging Face Transformers library, used for working with pre-trained models.\n",
        "\n",
        ">>**torchaudio:** Used for audio processing with PyTorch.\n",
        "\n",
        ">>**torch:** PyTorch deep learning library.\n",
        "\n",
        ">>**TextBlob:** A library for processing textual data, including sentiment analysis.\n",
        "\n",
        ">>**nltk:** Natural Language Toolkit, used for downloading corpora and datasets.\n",
        "\n",
        ">**Download NLTK Data :**\n",
        "The code downloads the brown corpus from NLTK using the nltk.download('brown') command. This corpus is used by TextBlob for language analysis.\n",
        "\n",
        ">**Initialize Models:**\n",
        "Two models are initialized:\n",
        ">>**ft_model:** FastText language detection model.\n",
        "\n",
        ">>**tokenizer** and **model**: Wav2Vec 2.0 models for speech recognition.\n",
        "\n",
        ">**Functions:**\n",
        ">>**recognize_speech_from_file:** Transcribes speech from an audio file using the Wav2Vec 2.0 model.\n",
        "\n",
        ">>**detect_language:** Detects the language of a given text using FastText.\n",
        "\n",
        ">>**analyze_sentiment:** Analyzes sentiment of a text using TextBlob.\n",
        "\n",
        ">>**detect_language_and_translate:** Detects the language of a text and provides a note if it's not in English.\n",
        "\n",
        ">>**extract_keywords:** Extracts key phrases from a text using TextBlob.\n",
        "\n",
        ">>**visualize_audio:** Visualizes the audio waveform from an audio file.\n",
        "\n",
        "\n",
        "> **The program processes the selected audio file in the following manner:**\n",
        "\n",
        ">>  Recognizes speech from the audio file.\n",
        "\n",
        ">>  Detects the language of the recognized text.\n",
        "\n",
        ">>  Translates the text if it's not in English.\n",
        "\n",
        ">>  Analyzes the sentiment of the text.\n",
        "\n",
        ">>  Provides feedback based on sentiment.\n",
        "\n",
        ">>  Extracts keywords from the text.\n",
        "\n",
        ">>  Prints the results.\n",
        "\n",
        ">>  Converts the feedback to speech and saves it as an audio file.\n",
        "\n",
        ">>  Visualizes the audio waveform of the selected file.\n",
        "\n",
        "\n",
        "This program is designed to perform audio transcription, language detection, sentiment analysis, and keyword extraction on selected audio files from Google Drive, providing feedback and visualizations along the way. It's a versatile tool for processing and analyzing spoken language.\n"
      ],
      "metadata": {
        "id": "i1l9Cngq406P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gtts"
      ],
      "metadata": {
        "id": "XQqWGqRu2tvD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fasttext"
      ],
      "metadata": {
        "id": "92gEsgTL21tg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers torchaudio"
      ],
      "metadata": {
        "id": "EHwTRdkX28fs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://dl.fbaipublicfiles.com/fasttext/supervised-models/lid.176.bin"
      ],
      "metadata": {
        "id": "8CxRszjy3haB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m textblob.download_corpora"
      ],
      "metadata": {
        "id": "_ZYVmlmU4Ciz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2pv65ACq2kjZ"
      },
      "outputs": [],
      "source": [
        "#************************************************************************************************\n",
        "# Developer: Eaby Kollonoor Babu\n",
        "# Version: 1.2\n",
        "# Last Updated: 2023-09-17\n",
        "# Contact:eaby.asha@gmail.com\n",
        "\n",
        "# Description\n",
        "\"\"\"\n",
        "A Speech Recognition and Synthesis Application using Python(for educational purpose only)\n",
        "\n",
        "Its a code that performs tasks like audio processing, language detection,\n",
        "sentiment analysis, from an input audio file..\n",
        "\"\"\"\n",
        "\n",
        "# License and Copyright Notice\n",
        "\"\"\"\n",
        "Copyright (c) 2023 Eaby Kollonoor Babu\n",
        "\n",
        "Permission is hereby granted, free of charge, to any person obtaining a copy of\n",
        "this software and associated documentation files (the \"Software\"), for the sole\n",
        "purpose of educational and non-commercial use, without restriction, including\n",
        "without limitation the rights to use, copy, modify, merge, publish, distribute,\n",
        "or sublicense copies of the Software, and to permit persons to whom the Software\n",
        "is furnished to do so, subject to the following conditions:\n",
        "\n",
        "The above copyright notice and this permission notice shall be included in all\n",
        "copies or substantial portions of the Software.\n",
        "\n",
        "THE SOFTWARE IS PROVIDED \"AS IS\" FOR EDUCATIONAL USE ONLY, WITHOUT WARRANTY OF ANY\n",
        "KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n",
        "MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE, AND NONINFRINGEMENT. IN NO\n",
        "EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR\n",
        "OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n",
        "FROM, OUT OF, OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS\n",
        "IN THE SOFTWARE.\n",
        "\"\"\"\n",
        "\n",
        "# Changelog/Release Notes\n",
        "\"\"\"\n",
        "Changelog:\n",
        "\n",
        "- Version 1.0 (2023-08-10): Basic speech Recognition program.\n",
        "- Version 1.1 (2023-08-13): Added speach Synthesis feature.\n",
        "- Version 1.2 (2023-09-17): Integrated language detection and sentiment analysis to the code.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "# Feedback\n",
        "\"\"\"\n",
        "For questions or feedback, feel free to email me at eaby.asha@gmail.com\n",
        "\"\"\"\n",
        "\n",
        "#************************************************************************************************\n",
        "\n",
        "\n",
        "# Import necessary libraries\n",
        "from google.colab import drive\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from gtts import gTTS\n",
        "import os\n",
        "import fasttext\n",
        "from transformers import Wav2Vec2ForCTC, Wav2Vec2Tokenizer\n",
        "import torchaudio\n",
        "import torch\n",
        "from textblob import TextBlob\n",
        "import nltk\n",
        "nltk.download('brown')\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Initialize the models\n",
        "\n",
        "# Initialize the FastText model for language detection\n",
        "ft_model = fasttext.load_model('lid.176.bin')\n",
        "\n",
        "# Initialize the wav2vec 2.0 model for speech recognition\n",
        "tokenizer = Wav2Vec2Tokenizer.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
        "model = Wav2Vec2ForCTC.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
        "model.eval()\n",
        "\n",
        "# Define functions\n",
        "\n",
        "def recognize_speech_from_file(file_path):\n",
        "    \"\"\"Transcribe speech from an audio file using wav2vec 2.0 and return the string.\"\"\"\n",
        "    waveform, rate = torchaudio.load(file_path, num_frames=10**7)\n",
        "    waveform = torchaudio.transforms.Resample(orig_freq=rate, new_freq=16000)(waveform)\n",
        "    input_values = tokenizer(waveform.squeeze().numpy(), return_tensors=\"pt\").input_values\n",
        "    with torch.no_grad():\n",
        "        logits = model(input_values).logits\n",
        "    predicted_ids = torch.argmax(logits, dim=-1)\n",
        "    transcription = tokenizer.decode(predicted_ids[0])\n",
        "    return transcription\n",
        "\n",
        "def detect_language(text):\n",
        "    \"\"\"Detect the language of the text using FastText.\"\"\"\n",
        "    predictions = ft_model.predict(text)\n",
        "    lang = predictions[0][0].split('__label__')[-1]\n",
        "    return lang\n",
        "\n",
        "def analyze_sentiment(text):\n",
        "    \"\"\"Analyze sentiment of the text and return the sentiment.\"\"\"\n",
        "    analysis = TextBlob(text)\n",
        "    if analysis.sentiment.polarity > 0.2:\n",
        "        return \"positive\"\n",
        "    elif analysis.sentiment.polarity < -0.2:\n",
        "        return \"negative\"\n",
        "    else:\n",
        "        return \"neutral\"\n",
        "\n",
        "def detect_language_and_translate(text):\n",
        "    \"\"\"Detect the language and inform if not English.\"\"\"\n",
        "    detected_lang = detect_language(text)\n",
        "    if detected_lang != 'en':\n",
        "        print(f\"Note: The detected language is {detected_lang.upper()}. Sentiment analysis might not be as accurate.\")\n",
        "    return text\n",
        "\n",
        "def extract_keywords(text, n=5):\n",
        "    \"\"\"Extract key phrases from the text.\"\"\"\n",
        "    blob = TextBlob(text)\n",
        "    return blob.noun_phrases[:n]\n",
        "\n",
        "def visualize_audio(file_path):\n",
        "    \"\"\"Visualize the audio waveform.\"\"\"\n",
        "    waveform, _ = torchaudio.load(file_path)\n",
        "    plt.figure(figsize=(10, 3))\n",
        "    plt.plot(waveform.t().numpy())\n",
        "    plt.title('Audio Waveform')\n",
        "    plt.xlabel('Sample')\n",
        "    plt.ylabel('Amplitude')\n",
        "    plt.show()\n",
        "\n",
        "# Ask the user to select a file\n",
        "\n",
        "files = [\n",
        "    \"/content/drive/My Drive/MyData/harvard.wav\",\n",
        "    \"/content/drive/My Drive/MyData/sample2eng.wav\",\n",
        "    \"/content/drive/My Drive/MyData/sample3fr.wav\"\n",
        "]\n",
        "\n",
        "print(\"Please select a file to process:\")\n",
        "for i, file in enumerate(files, 1):\n",
        "    print(f\"{i}. {file.split('/')[-1]}\")\n",
        "\n",
        "try:\n",
        "    selected_index = int(input(\"Enter the number corresponding to your file choice: \")) - 1\n",
        "    if 0 <= selected_index < len(files):\n",
        "        file_path = files[selected_index]\n",
        "    else:\n",
        "        print(\"Invalid choice!\")\n",
        "        raise ValueError(\"Invalid file choice\")\n",
        "\n",
        "    # Process the selected .wav file and perform sentiment analysis\n",
        "\n",
        "    # Recognize speech\n",
        "    text = recognize_speech_from_file(file_path)\n",
        "\n",
        "    if text:\n",
        "        # Language detection\n",
        "        detected_language = detect_language(text)\n",
        "        print(\"\\nLanguage Detected:\", detected_language.upper())\n",
        "\n",
        "        # Translation (if needed)\n",
        "        translated_text = detect_language_and_translate(text)\n",
        "\n",
        "        # Sentiment analysis\n",
        "        sentiment = analyze_sentiment(translated_text)\n",
        "\n",
        "        # Feedback based on sentiment\n",
        "        if sentiment == \"positive\":\n",
        "            feedback = \"That sounds positive! Keep up the good vibes.\"\n",
        "        elif sentiment == \"negative\":\n",
        "            feedback = \"That sounds a bit negative. Everything will be alright!\"\n",
        "        else:\n",
        "            feedback = \"That sounds neutral. Tell me more!\"\n",
        "\n",
        "        # Keyword extraction\n",
        "        keywords = extract_keywords(translated_text)\n",
        "\n",
        "        # Print results\n",
        "        print(\"Recognized Text:\", text)\n",
        "        if text != translated_text:\n",
        "            print(\"Translated Text:\", translated_text)\n",
        "        print(\"Sentiment Detected:\", sentiment)\n",
        "        print(\"Feedback:\", feedback)\n",
        "        print(\"Keywords:\", ', '.join(keywords))\n",
        "\n",
        "        # Text-to-Speech synthesis\n",
        "        tts = gTTS(feedback, lang='en')\n",
        "        output_path = \"/content/drive/My Drive/MyData/feedback_audio_output.wav\"\n",
        "        tts.save(output_path)\n",
        "        print(f\"Feedback audio saved to: {output_path}\")\n",
        "\n",
        "        # Visualize audio\n",
        "        visualize_audio(file_path)\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")"
      ]
    }
  ]
}